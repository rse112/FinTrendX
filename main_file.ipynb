{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib, hmac, base64\n",
    "from itertools import combinations, permutations\n",
    "from dtw import *\n",
    "import json\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "from pytz import timezone\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from collections import defaultdict\n",
    "from pytrends.request import TrendReq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. API설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_set import APIClient\n",
    "\n",
    "# API 설정\n",
    "from utils import get_secret\n",
    "BASE_URL = get_secret(\"BASE_URL\")\n",
    "CUSTOMER_ID = get_secret(\"CUSTOMER_ID\")\n",
    "API_KEY = get_secret(\"API_KEY\")\n",
    "SECRET_KEY = get_secret(\"SECRET_KEY\")\n",
    "URI = get_secret(\"URI\")\n",
    "METHOD = get_secret(\"METHOD\")\n",
    "# API 클라이언트 인스턴스 생성\n",
    "api_client = APIClient(BASE_URL, CUSTOMER_ID, API_KEY, SECRET_KEY,URI,METHOD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 연관검색어 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키 로드\n",
    "from utils import load_keywords \n",
    "keywords_data = load_keywords('main_keyword.json')\n",
    "\n",
    "from utils import get_today_date\n",
    "# 오늘의 날짜 가져오기\n",
    "formatted_today, day = get_today_date()\n",
    "\n",
    "\n",
    "# 결과 저장 폴더 생성\n",
    "from utils import make_directory\n",
    "\n",
    "make_directory('./data')\n",
    "make_directory('./data/rl_srch')\n",
    "make_directory(f'./data/rl_srch/{day}')  # 키워드별 연관검색어 리스트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.searchad.naver.com\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 검색어 리스트와 결과 저장 경로 설정\n",
    "srch_keyword = ['keyword_final']  \n",
    "save_path = './data/rl_srch/'  \n",
    "print(api_client.base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['keyword_final']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srch_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "\n",
    "# 필요한 경우 비동기를 위한 nest_asyncio 적용\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from collect_keywords import collect_keywords\n",
    "\n",
    "async def main(srch_keyword, day):\n",
    "    # 오늘 날짜로 폴더 경로 생성\n",
    "    folder_path = './data/rl_srch/' + datetime.datetime.now().strftime('%y%m%d')\n",
    "    file_path = f\"{folder_path}/collected_keywords.csv\"\n",
    "    \n",
    "    # 폴더가 존재하는지 확인\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    # 파일이 존재하는지 확인\n",
    "    if os.path.isfile(file_path):\n",
    "        # 파일이 존재하면, 데이터를 읽어옵니다.\n",
    "        collected_keywords_data = pd.read_csv(file_path)\n",
    "    else:\n",
    "        # 파일이 없으면, collect_keywords 함수를 호출해서 데이터를 수집합니다.\n",
    "        collected_keywords_data = await collect_keywords(srch_keyword, day)\n",
    "        # 결과를 CSV로 저장\n",
    "        collected_keywords_data.to_csv(file_path, index=False)\n",
    "    \n",
    "    return collected_keywords_data\n",
    "collected_keywords_data=asyncio.run(main(srch_keyword, day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         연관키워드  월간검색수_합계 검색어\n",
      "0           주식  528500.0  주식\n",
      "1          미주부     370.0  주식\n",
      "2        김현준대표     940.0  주식\n",
      "3         퀀트투자    6650.0  주식\n",
      "4         주식투자   12310.0  주식\n",
      "...        ...       ...  ..\n",
      "30599   수원유언공증      18.0  증여\n",
      "30600   법인주소변경    1940.0  증여\n",
      "30601   인터넷법무사     460.0  증여\n",
      "30602    환지예정지     330.0  증여\n",
      "30603  지정유언집행자      80.0  증여\n",
      "\n",
      "[30604 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(collected_keywords_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 키워드 트렌드 및 패턴 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 정보지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datetime' has no attribute 'now'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# 날짜 지정\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m today \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnow\u001b[49m(timezone(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsia/Seoul\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m day \u001b[38;5;241m=\u001b[39m today\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# 저장할 폴더 미리 생성, 폴더가 이미 있으면 생성하지 않음\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'datetime' has no attribute 'now'"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "    # 날짜 지정\n",
    "today = datetime.now(timezone('Asia/Seoul'))\n",
    "day = today.strftime(\"%y%m%d\")  \n",
    "\n",
    "    # 저장할 폴더 미리 생성, 폴더가 이미 있으면 생성하지 않음\n",
    "folders_to_create = [\n",
    "        './data/tmp',\n",
    "        './data/result',\n",
    "        f'./data/result/{day}',\n",
    "        f'./data/result/{day}/graph'\n",
    "    ]\n",
    "\n",
    "for folder in folders_to_create:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # 분석 기간 설정\n",
    "start_index = (today - relativedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "end_index = (today - relativedelta(years=3) - relativedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "print(['분석시작일:', start_index, '분석종료일:', end_index])\n",
    "\n",
    "    # URI 정보 가져오기\n",
    "URI = utils.get_secret(\"URI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 상세 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress_log.txt has been deleted.\n",
      "progress_state.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "# 삭제할 파일 경로 정의\n",
    "progress_log_path = 'progress_log.txt'  # 가정: 실제 경로에 맞게 수정해야 함\n",
    "progress_state_path = 'progress_state.json'  # 가정: 실제 경로에 맞게 수정해야 함\n",
    "\n",
    "# progress_log 파일 삭제\n",
    "if os.path.exists(progress_log_path):\n",
    "    os.remove(progress_log_path)\n",
    "    print(f'{progress_log_path} has been deleted.')\n",
    "else:\n",
    "    print(f'{progress_log_path} does not exist.')\n",
    "\n",
    "# progress_state.json 파일 삭제\n",
    "if os.path.exists(progress_state_path):\n",
    "    os.remove(progress_state_path)\n",
    "    print(f'{progress_state_path} has been deleted.')\n",
    "else:\n",
    "    print(f'{progress_state_path} does not exist.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trend_data : 상대지표\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import utils\n",
    "from trend import trend_maincode\n",
    "import time\n",
    "from pytz import timezone\n",
    "import select_keyword\n",
    "\n",
    "class analysis:\n",
    "    def __init__(self):\n",
    "        # 기본설정\n",
    "        self.formatted_today, self.day=utils.get_today_date()\n",
    "        self.state=utils.load_state()\n",
    "        self.apiCallCount = self.state.get('api_request_count', 1)\n",
    "        self.current_client_index = self.state.get('current_client_index', 0)\n",
    "        self.keywords = utils.load_keywords('main_keyword.json')['keyword_final']\n",
    "        self.request_limit = 1000\n",
    "        self.keyword_index = self.state['keyword_index']\n",
    "        self.standard_time = datetime.now()\n",
    "        self.api_url = \"https://openapi.naver.com/v1/datalab/search\"\n",
    "        self.today = datetime.now(timezone('Asia/Seoul'))\n",
    "        self.api_request_data = pd.DataFrame(columns=['search_keywords'])\n",
    "        self.start_index = (self.today - relativedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        self.end_index = (self.today - relativedelta(years=3) - relativedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        self.clients = utils.get_secret(\"clients\")\n",
    "        \n",
    "\n",
    "        self.api_request_data_dataname = {\n",
    "                'api_request_data': [],\n",
    "                'keyname': []\n",
    "        }\n",
    "\n",
    "        # 데이터프레임 초기화\n",
    "        self.trends_dataframes = {\n",
    "        'daily_up': pd.DataFrame(),\n",
    "        'weekly_up': pd.DataFrame(),\n",
    "        'weekly_stay': pd.DataFrame(),\n",
    "        'monthly_up': pd.DataFrame(),\n",
    "        'monthly_stay': pd.DataFrame(),\n",
    "        'monthly_rule': pd.DataFrame()\n",
    "        }\n",
    "\n",
    "\n",
    "        self.graph_tables = {\n",
    "        'day': pd.DataFrame(index=pd.date_range(start=self.start_index, end=self.end_index, freq='1d')),\n",
    "        'week': pd.DataFrame(index=pd.date_range(start=self.start_index, end=self.end_index, freq='7d')),\n",
    "        'month': pd.DataFrame(index=pd.date_range(start=self.start_index, end=self.end_index, freq='28d'))\n",
    "        }\n",
    "\n",
    "        # 정보 저장을 위한 딕셔너리 초기화\n",
    "        self.keyword_data = {\n",
    "            'keyword_categories': {},\n",
    "            'related_search_terms': {},\n",
    "            'related_search_volume': {},\n",
    "            'up_month': {}\n",
    "        }\n",
    "        self.review_types = {\n",
    "                'daily': {\n",
    "                        'function': select_keyword.select_keyword,\n",
    "                        'info_dict': {},\n",
    "                        'trend_df': self.trends_dataframes['daily_up'],\n",
    "                        'graph_df': self.graph_tables['day'],\n",
    "                        'time_period': 'daily'\n",
    "                    },\n",
    "            'weekly_up': {\n",
    "                        'function': select_keyword.select_keyword,\n",
    "                        'info_dict': {},\n",
    "                        'trend_df': self.trends_dataframes['weekly_up'],\n",
    "                        'graph_df': self.graph_tables['week'],\n",
    "                        'time_period': 'weekly'\n",
    "                    },\n",
    "            'weekly_stay': {\n",
    "                        'function': select_keyword.rising_keyword_analysis,\n",
    "                        'info_dict': {},\n",
    "                        'trend_df': self.trends_dataframes['weekly_stay'],\n",
    "                        'graph_df': self.graph_tables['month'],\n",
    "                        'time_period': 'weekly'\n",
    "                    },\n",
    "            'monthly_up': {\n",
    "                        'function': select_keyword.select_keyword,\n",
    "                        'info_dict': {},\n",
    "                        'trend_df': self.trends_dataframes['monthly_up'],\n",
    "                        'graph_df': self.graph_tables['month'],\n",
    "                        'time_period': 'month'\n",
    "                    },\n",
    "            'monthly_stay': {\n",
    "                        'function': select_keyword.rising_keyword_analysis,\n",
    "                        'info_dict': {},\n",
    "                        'trend_df': self.trends_dataframes['monthly_stay'],\n",
    "                        'graph_df': self.graph_tables['month'],\n",
    "                        'time_period': 'month'\n",
    "                    },\n",
    "            'monthly_rule': {\n",
    "                        'function': select_keyword.monthly_rule,\n",
    "                        'info_dict': {},\n",
    "                        'trend_df': self.trends_dataframes['monthly_rule'],\n",
    "                        'graph_df': self.graph_tables['month'],\n",
    "                        'time_period': 'month'\n",
    "                    }\n",
    "                }\n",
    "        pass\n",
    "\n",
    "\n",
    "        # api 설정\n",
    "    def handle_api_call(self,keywordName,df_table,currentRequestCount):\n",
    "        if self.apiCallCount<= self.request_limit:\n",
    "            id_num,pw,_=utils.get_client_info(self.clients,self.current_client_index)\n",
    "            id = self.clients[id_num]['client_id']\n",
    "            pw=self.clients[id_num]['client_secret']\n",
    "            utils.log_progress(keywordName, currentRequestCount, \\\n",
    "                               len(df_table), id, self.apiCallCount, self.request_limit)\n",
    "            related_keyword = df_table['연관키워드'][currentRequestCount]\n",
    "            request_data = {\n",
    "            \n",
    "            'search_keywords': related_keyword,\n",
    "\n",
    "            }        \n",
    "            return request_data, self.apiCallCount + 1, self.current_client_index\n",
    "        else:\n",
    "                # 요청 한도 초과 시 클라이언트 인덱스 업데이트\n",
    "                self.current_client_index += 1\n",
    "                if self.current_client_index >= len(self.clients):\n",
    "                    print(\"모든 API 클라이언트의 요청 한도 초과\")\n",
    "                    return None, self.apiCallCount, self.current_client_index  # 처리 중단을 위한 None 반환\n",
    "                else:\n",
    "                    # 클라이언트 전환 후 재시도\n",
    "                    return self.handle_api_call(keywordName, currentRequestCount, df_table)\n",
    "                \n",
    "    # 연관 검색어의 trend 데이터\n",
    "    def analyze_trend_data(self, uniq):\n",
    "        params = {\n",
    "            \"search_keywords\": uniq[\"api_request_data\"],  \n",
    "            \"id\": self.clients['id_1'][\"client_id\"],\n",
    "            \"pw\": self.clients['id_1'][\"client_secret\"],\n",
    "            \"api_url\": self.api_url\n",
    "        }\n",
    "        trend_data = asyncio.run(trend_maincode(params,self.clients, self.api_url))\n",
    "        return trend_data\n",
    "    \n",
    "    # 연관검색어의 급상승, 지속상승 로직 적용\n",
    "    def select_keywords(self, trend_data):\n",
    "        review_settings = {key: [] for key in self.review_types.keys()}\n",
    "        for i, (index, row) in enumerate(trend_data.iterrows()):\n",
    "            # 각 행의 첫 번째 열과 두 번째 열의 값 참조\n",
    "            first_column_value = row['trend_data']\n",
    "            second_column_value = row['keyname']\n",
    "            \n",
    "            for review_key, settings in self.review_types.items():\n",
    "                if review_key == 'monthly_rule':\n",
    "                    # monthly_rule에 대한 특별 처리\n",
    "                    trend_analysis_df, graph_data_df, analysis_info, rising_month = settings['function'](first_column_value, self.day, settings['time_period'])\n",
    "                    if trend_analysis_df is not None:\n",
    "                        review_settings[review_key].append((trend_analysis_df, graph_data_df, analysis_info, rising_month, second_column_value,first_column_value.columns[0]))\n",
    "                else:\n",
    "                    # 기타 경우 처리\n",
    "                    trend_analysis_df, graph_data_df, analysis_info = settings['function'](first_column_value, self.day, settings['time_period'])\n",
    "                    if trend_analysis_df is not None:\n",
    "                        review_settings[review_key].append((trend_analysis_df, graph_data_df, analysis_info, second_column_value,first_column_value.columns[0]))\n",
    "        return review_settings\n",
    "                            # tmp 랑 tmp_gph, tmp_info 얘네를 딕셔너리에 집어넣는 함수\n",
    "\n",
    "    #     #딕셔너리에 데이터를 넣는 함수\n",
    "    def insert_data_into_dict(self):\n",
    "        \n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    def collect_and_analyze_keyword_trends(self):\n",
    "        total_keywords = len(self.keywords)\n",
    "        api_request_data_list = []  # DataFrame 대신 사용할 리스트\n",
    "\n",
    "        for keywordIndex, keywordName in enumerate(self.keywords[self.keyword_index:], start=self.keyword_index):\n",
    "            df_table = pd.read_csv(f'./data/rl_srch/{self.day}/{keywordName}.csv', encoding='euc-kr')\n",
    "            print(f'################################################ {keywordName} ({keywordIndex+1}/{total_keywords}) ################################################')\n",
    "            maxKeyword = min(50, len(df_table))\n",
    "\n",
    "            for currentRequestCount in range(self.state['currentRequestCount_index'], maxKeyword):\n",
    "                request_data, self.apiCallCount, self.current_client_index = self.handle_api_call(keywordName, df_table, currentRequestCount)\n",
    "                self.api_request_data_dataname['keyname'].append(keywordName)\n",
    "                # API 요청 예외 처리 (한도 초과 시 클라이언트 인덱스 업데이트)\n",
    "                if request_data is not None:\n",
    "                    api_request_data_list.append(request_data)  # 리스트에 데이터 추가\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if self.current_client_index >= len(self.clients):\n",
    "                print(\"모든 API 클라이언트의 요청 한도 초과\")\n",
    "                break\n",
    "\n",
    "            self.keyword_index += 1\n",
    "\n",
    "        # 리스트를 DataFrame으로 변환\n",
    "            \n",
    "        if api_request_data_list:\n",
    "            self.api_request_data = pd.DataFrame(api_request_data_list)\n",
    "            api_data_list = self.api_request_data['search_keywords'].tolist()\n",
    "\n",
    "            self.api_request_data_dataname['api_request_data'] = api_data_list\n",
    "        print(f'API 요청 데이터 수: {len(self.api_request_data)}')\n",
    "\n",
    "\n",
    "        uniq=utils.merge_keys_for_unique_names(self.api_request_data_dataname)\n",
    "        trend_data = pd.DataFrame({'trend_data': self.analyze_trend_data(uniq), 'keyname': uniq['keyname']})\n",
    "        return trend_data\n",
    "        # 실시간 급상승 이런거 들어가는 함수부분\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/rl_srch/240307/주식.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m start\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      2\u001b[0m analysis_instance \u001b[38;5;241m=\u001b[39m analysis()\n\u001b[1;32m----> 3\u001b[0m trend_data\u001b[38;5;241m=\u001b[39m\u001b[43manalysis_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_and_analyze_keyword_trends\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart)\n",
      "Cell \u001b[1;32mIn[14], line 176\u001b[0m, in \u001b[0;36manalysis.collect_and_analyze_keyword_trends\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m api_request_data_list \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# DataFrame 대신 사용할 리스트\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m keywordIndex, keywordName \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeywords[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeyword_index:], start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeyword_index):\n\u001b[1;32m--> 176\u001b[0m     df_table \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/rl_srch/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mday\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkeywordName\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meuc-kr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m################################################ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeywordName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeywordIndex\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_keywords\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) ################################################\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    178\u001b[0m     maxKeyword \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_table))\n",
      "File \u001b[1;32mc:\\Users\\chohy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1012\u001b[0m     dialect,\n\u001b[0;32m   1013\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chohy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\chohy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chohy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\chohy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/rl_srch/240307/주식.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start=time.time()\n",
    "analysis_instance = analysis()\n",
    "trend_data=analysis_instance.collect_and_analyze_keyword_trends()\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "월별 급상승 키워드 발견 : ISA계좌\n",
      "월별 급상승 키워드 발견 : AI관련주\n",
      "주별 지속상승 키워드 발견 : ETF\n",
      "일별 급상승 키워드 발견: 퇴직연금\n",
      "월별 급상승 키워드 발견 : IRP계좌개설\n",
      "월별 지속상승 키워드 발견 : IRP계좌개설\n",
      "월별 급상승 키워드 발견 : CMA통장\n",
      "월별 지속상승 키워드 발견 : CMA통장\n",
      "일별 급상승 키워드 발견: ETF투자방법\n",
      "월별 급상승 키워드 발견: 배당주\n",
      "월별 급상승 키워드 발견 : 파킹통장\n",
      "일별 급상승 키워드 발견: 비트코인전망\n",
      "주별 급상승 키워드 발견: 비트코인전망\n",
      "월별 급상승 키워드 발견 : 파킹통장금리비교\n",
      "월별 지속상승 키워드 발견 : 파킹통장금리비교\n",
      "일별 급상승 키워드 발견: 샌드박스코인\n",
      "주별 급상승 키워드 발견: 샌드박스코인\n",
      "월별 급상승 키워드 발견 : 해외주식\n"
     ]
    }
   ],
   "source": [
    "result_dict=analysis_instance.select_keywords(trend_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['monthly_rule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[            기준일자     유형 연관검색어       검색일자        검색량\n",
       "  0     2024-03-06  일별급상승  퇴직연금 2021-03-05   37.96186\n",
       "  1     2024-03-06  일별급상승  퇴직연금 2021-03-06   17.85051\n",
       "  2     2024-03-06  일별급상승  퇴직연금 2021-03-07   19.38586\n",
       "  3     2024-03-06  일별급상승  퇴직연금 2021-03-08   44.54192\n",
       "  4     2024-03-06  일별급상승  퇴직연금 2021-03-09   44.87936\n",
       "  ...          ...    ...   ...        ...        ...\n",
       "  1092  2024-03-06  일별급상승  퇴직연금 2024-03-01   20.78623\n",
       "  1093  2024-03-06  일별급상승  퇴직연금 2024-03-02   16.34891\n",
       "  1094  2024-03-06  일별급상승  퇴직연금 2024-03-03   16.85507\n",
       "  1095  2024-03-06  일별급상승  퇴직연금 2024-03-04   76.93605\n",
       "  1096  2024-03-06  일별급상승  퇴직연금 2024-03-05  100.00000\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "              기준일자     유형 연관검색어       검색일자        검색량\n",
       "  0     2024-03-06  일별급상승  퇴직연금 2021-03-05   37.96186\n",
       "  1     2024-03-06  일별급상승  퇴직연금 2021-03-06   17.85051\n",
       "  2     2024-03-06  일별급상승  퇴직연금 2021-03-07   19.38586\n",
       "  3     2024-03-06  일별급상승  퇴직연금 2021-03-08   44.54192\n",
       "  4     2024-03-06  일별급상승  퇴직연금 2021-03-09   44.87936\n",
       "  ...          ...    ...   ...        ...        ...\n",
       "  1092  2024-03-06  일별급상승  퇴직연금 2024-03-01   20.78623\n",
       "  1093  2024-03-06  일별급상승  퇴직연금 2024-03-02   16.34891\n",
       "  1094  2024-03-06  일별급상승  퇴직연금 2024-03-03   16.85507\n",
       "  1095  2024-03-06  일별급상승  퇴직연금 2024-03-04   76.93605\n",
       "  1096  2024-03-06  일별급상승  퇴직연금 2024-03-05  100.00000\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "  29.98,\n",
       "  ['주식'],\n",
       "  '퇴직연금',\n",
       "  67500.0,\n",
       "  67500.0],\n",
       " [            기준일자     유형    연관검색어       검색일자       검색량\n",
       "  0     2024-03-06  일별급상승  ETF투자방법 2021-03-05   6.71328\n",
       "  1     2024-03-06  일별급상승  ETF투자방법 2021-03-06   7.17948\n",
       "  2     2024-03-06  일별급상승  ETF투자방법 2021-03-07   9.13752\n",
       "  3     2024-03-06  일별급상승  ETF투자방법 2021-03-08  11.74825\n",
       "  4     2024-03-06  일별급상승  ETF투자방법 2021-03-09  11.56177\n",
       "  ...          ...    ...      ...        ...       ...\n",
       "  1092  2024-03-06  일별급상승  ETF투자방법 2024-03-01  45.17482\n",
       "  1093  2024-03-06  일별급상승  ETF투자방법 2024-03-02  43.91608\n",
       "  1094  2024-03-06  일별급상승  ETF투자방법 2024-03-03  40.32634\n",
       "  1095  2024-03-06  일별급상승  ETF투자방법 2024-03-04  63.21678\n",
       "  1096  2024-03-06  일별급상승  ETF투자방법 2024-03-05  98.32167\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "              기준일자     유형    연관검색어       검색일자       검색량\n",
       "  0     2024-03-06  일별급상승  ETF투자방법 2021-03-05   6.71328\n",
       "  1     2024-03-06  일별급상승  ETF투자방법 2021-03-06   7.17948\n",
       "  2     2024-03-06  일별급상승  ETF투자방법 2021-03-07   9.13752\n",
       "  3     2024-03-06  일별급상승  ETF투자방법 2021-03-08  11.74825\n",
       "  4     2024-03-06  일별급상승  ETF투자방법 2021-03-09  11.56177\n",
       "  ...          ...    ...      ...        ...       ...\n",
       "  1092  2024-03-06  일별급상승  ETF투자방법 2024-03-01  45.17482\n",
       "  1093  2024-03-06  일별급상승  ETF투자방법 2024-03-02  43.91608\n",
       "  1094  2024-03-06  일별급상승  ETF투자방법 2024-03-03  40.32634\n",
       "  1095  2024-03-06  일별급상승  ETF투자방법 2024-03-04  63.21678\n",
       "  1096  2024-03-06  일별급상승  ETF투자방법 2024-03-05  98.32167\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "  55.53,\n",
       "  ['주식'],\n",
       "  'ETF투자방법',\n",
       "  34670.0,\n",
       "  34670.0],\n",
       " [            기준일자     유형   연관검색어       검색일자       검색량\n",
       "  0     2024-03-06  일별급상승  비트코인전망 2021-03-05   8.49893\n",
       "  1     2024-03-06  일별급상승  비트코인전망 2021-03-06   6.47183\n",
       "  2     2024-03-06  일별급상승  비트코인전망 2021-03-07   6.66312\n",
       "  3     2024-03-06  일별급상승  비트코인전망 2021-03-08   6.82252\n",
       "  4     2024-03-06  일별급상승  비트코인전망 2021-03-09   9.01434\n",
       "  ...          ...    ...     ...        ...       ...\n",
       "  1092  2024-03-06  일별급상승  비트코인전망 2024-03-01   8.11902\n",
       "  1093  2024-03-06  일별급상승  비트코인전망 2024-03-02   7.04569\n",
       "  1094  2024-03-06  일별급상승  비트코인전망 2024-03-03   6.69234\n",
       "  1095  2024-03-06  일별급상승  비트코인전망 2024-03-04  10.57651\n",
       "  1096  2024-03-06  일별급상승  비트코인전망 2024-03-05  19.40488\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "              기준일자     유형   연관검색어       검색일자       검색량\n",
       "  0     2024-03-06  일별급상승  비트코인전망 2021-03-05   8.49893\n",
       "  1     2024-03-06  일별급상승  비트코인전망 2021-03-06   6.47183\n",
       "  2     2024-03-06  일별급상승  비트코인전망 2021-03-07   6.66312\n",
       "  3     2024-03-06  일별급상승  비트코인전망 2021-03-08   6.82252\n",
       "  4     2024-03-06  일별급상승  비트코인전망 2021-03-09   9.01434\n",
       "  ...          ...    ...     ...        ...       ...\n",
       "  1092  2024-03-06  일별급상승  비트코인전망 2024-03-01   8.11902\n",
       "  1093  2024-03-06  일별급상승  비트코인전망 2024-03-02   7.04569\n",
       "  1094  2024-03-06  일별급상승  비트코인전망 2024-03-03   6.69234\n",
       "  1095  2024-03-06  일별급상승  비트코인전망 2024-03-04  10.57651\n",
       "  1096  2024-03-06  일별급상승  비트코인전망 2024-03-05  19.40488\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "  83.47,\n",
       "  ['금리'],\n",
       "  '비트코인전망',\n",
       "  78540.0,\n",
       "  78540.0],\n",
       " [            기준일자     유형   연관검색어       검색일자        검색량\n",
       "  0     2024-03-06  일별급상승  샌드박스코인 2021-03-05   6.690403\n",
       "  1     2024-03-06  일별급상승  샌드박스코인 2021-03-06   3.229489\n",
       "  2     2024-03-06  일별급상승  샌드박스코인 2021-03-07   2.618435\n",
       "  3     2024-03-06  일별급상승  샌드박스코인 2021-03-08   4.615402\n",
       "  4     2024-03-06  일별급상승  샌드박스코인 2021-03-09  10.177328\n",
       "  ...          ...    ...     ...        ...        ...\n",
       "  1092  2024-03-06  일별급상승  샌드박스코인 2024-03-01   6.963437\n",
       "  1093  2024-03-06  일별급상승  샌드박스코인 2024-03-02   9.199649\n",
       "  1094  2024-03-06  일별급상승  샌드박스코인 2024-03-03   7.969720\n",
       "  1095  2024-03-06  일별급상승  샌드박스코인 2024-03-04   8.500147\n",
       "  1096  2024-03-06  일별급상승  샌드박스코인 2024-03-05  11.877884\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "              기준일자     유형   연관검색어       검색일자        검색량\n",
       "  0     2024-03-06  일별급상승  샌드박스코인 2021-03-05   6.690403\n",
       "  1     2024-03-06  일별급상승  샌드박스코인 2021-03-06   3.229489\n",
       "  2     2024-03-06  일별급상승  샌드박스코인 2021-03-07   2.618435\n",
       "  3     2024-03-06  일별급상승  샌드박스코인 2021-03-08   4.615402\n",
       "  4     2024-03-06  일별급상승  샌드박스코인 2021-03-09  10.177328\n",
       "  ...          ...    ...     ...        ...        ...\n",
       "  1092  2024-03-06  일별급상승  샌드박스코인 2024-03-01   6.963437\n",
       "  1093  2024-03-06  일별급상승  샌드박스코인 2024-03-02   9.199649\n",
       "  1094  2024-03-06  일별급상승  샌드박스코인 2024-03-03   7.969720\n",
       "  1095  2024-03-06  일별급상승  샌드박스코인 2024-03-04   8.500147\n",
       "  1096  2024-03-06  일별급상승  샌드박스코인 2024-03-05  11.877884\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "  39.74,\n",
       "  ['금리'],\n",
       "  '샌드박스코인',\n",
       "  45210.0,\n",
       "  45210.0]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_list=['daily','weekly_up','weekly_stay','monthly_up','monthly_stay','monthly_rule']\n",
    "def assign_value_to_result_dict(mode, num, value):\n",
    "    \"\"\"result_dict의 각 항목 끝에 value를 추가합니다.\"\"\"\n",
    "    # 현재 항목을 리스트로 변환 (튜플일 경우)\n",
    "    current_item = list(result_dict[mode][num])\n",
    "    # value를 리스트 끝에 추가\n",
    "    current_item.append(value)\n",
    "    # 변경된 리스트를 다시 result_dict에 할당\n",
    "    result_dict[mode][num] = current_item\n",
    "\n",
    "\n",
    "for mode in mode_list:\n",
    "    n = result_dict[mode]\n",
    "    for num in range(len(n)):\n",
    "        keyword = result_dict[mode][num][4] if mode != 'monthly_rule' else result_dict[mode][num][5]\n",
    "        keyword_exists = (collected_keywords_data['연관키워드'] == keyword).any()\n",
    "        \n",
    "        if keyword_exists:\n",
    "            filtered_data = collected_keywords_data[collected_keywords_data['연관키워드'] == keyword]\n",
    "            if not filtered_data.empty:  # 필터링된 데이터프레임이 비어있지 않은지 확인\n",
    "                value = filtered_data['월간검색수_합계'].iloc[0]  # 원하는 값\n",
    "                assign_value_to_result_dict(mode, num, value)  # 값을 result_dict에 할당\n",
    "\n",
    "\n",
    "\n",
    "result_dict['daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = result_dict[mode][num][4] if mode != 'monthly_rule' else result_dict[mode][num][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_list=['daily','weekly_up','weekly_stay','monthly_up','monthly_stay','monthly_rule']\n",
    "def assign_value_to_result_dict(mode, num, value):\n",
    "    \"\"\"result_dict의 각 항목 끝에 value를 추가합니다.\"\"\"\n",
    "    # 현재 항목을 리스트로 변환 (튜플일 경우)\n",
    "    current_item = list(result_dict[mode][num])\n",
    "    # value를 리스트 끝에 추가\n",
    "    current_item.append(value)\n",
    "    # 변경된 리스트를 다시 result_dict에 할당\n",
    "    result_dict[mode][num] = current_item\n",
    "\n",
    "\n",
    "for mode in mode_list:\n",
    "    n = result_dict[mode]\n",
    "    for num in range(len(n)):\n",
    "        keyword = ...  # keyword 결정 로직 (예시 데이터 필요)\n",
    "        keyword_exists = (collected_keywords_data['연관키워드'] == keyword).any()\n",
    "        \n",
    "        if keyword_exists:\n",
    "            filtered_data = collected_keywords_data[collected_keywords_data['연관키워드'] == keyword]\n",
    "            if not filtered_data.empty:  # 필터링된 데이터프레임이 비어있지 않은지 확인\n",
    "                value = filtered_data['월간검색수_합계'].iloc[0]  # 원하는 값\n",
    "                print(1)\n",
    "                assign_value_to_result_dict(mode, num, value)  # 값을 result_dict에 할당\n",
    "\n",
    "\n",
    "\n",
    "result_dict['daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[            기준일자     유형 연관검색어       검색일자        검색량\n",
       "  0     2024-03-06  일별급상승  퇴직연금 2021-03-05   37.96186\n",
       "  1     2024-03-06  일별급상승  퇴직연금 2021-03-06   17.85051\n",
       "  2     2024-03-06  일별급상승  퇴직연금 2021-03-07   19.38586\n",
       "  3     2024-03-06  일별급상승  퇴직연금 2021-03-08   44.54192\n",
       "  4     2024-03-06  일별급상승  퇴직연금 2021-03-09   44.87936\n",
       "  ...          ...    ...   ...        ...        ...\n",
       "  1092  2024-03-06  일별급상승  퇴직연금 2024-03-01   20.78623\n",
       "  1093  2024-03-06  일별급상승  퇴직연금 2024-03-02   16.34891\n",
       "  1094  2024-03-06  일별급상승  퇴직연금 2024-03-03   16.85507\n",
       "  1095  2024-03-06  일별급상승  퇴직연금 2024-03-04   76.93605\n",
       "  1096  2024-03-06  일별급상승  퇴직연금 2024-03-05  100.00000\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "              기준일자     유형 연관검색어       검색일자        검색량\n",
       "  0     2024-03-06  일별급상승  퇴직연금 2021-03-05   37.96186\n",
       "  1     2024-03-06  일별급상승  퇴직연금 2021-03-06   17.85051\n",
       "  2     2024-03-06  일별급상승  퇴직연금 2021-03-07   19.38586\n",
       "  3     2024-03-06  일별급상승  퇴직연금 2021-03-08   44.54192\n",
       "  4     2024-03-06  일별급상승  퇴직연금 2021-03-09   44.87936\n",
       "  ...          ...    ...   ...        ...        ...\n",
       "  1092  2024-03-06  일별급상승  퇴직연금 2024-03-01   20.78623\n",
       "  1093  2024-03-06  일별급상승  퇴직연금 2024-03-02   16.34891\n",
       "  1094  2024-03-06  일별급상승  퇴직연금 2024-03-03   16.85507\n",
       "  1095  2024-03-06  일별급상승  퇴직연금 2024-03-04   76.93605\n",
       "  1096  2024-03-06  일별급상승  퇴직연금 2024-03-05  100.00000\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "  29.98,\n",
       "  ['주식'],\n",
       "  '퇴직연금',\n",
       "  67500.0,\n",
       "  67500.0],\n",
       " [            기준일자     유형    연관검색어       검색일자       검색량\n",
       "  0     2024-03-06  일별급상승  ETF투자방법 2021-03-05   6.71328\n",
       "  1     2024-03-06  일별급상승  ETF투자방법 2021-03-06   7.17948\n",
       "  2     2024-03-06  일별급상승  ETF투자방법 2021-03-07   9.13752\n",
       "  3     2024-03-06  일별급상승  ETF투자방법 2021-03-08  11.74825\n",
       "  4     2024-03-06  일별급상승  ETF투자방법 2021-03-09  11.56177\n",
       "  ...          ...    ...      ...        ...       ...\n",
       "  1092  2024-03-06  일별급상승  ETF투자방법 2024-03-01  45.17482\n",
       "  1093  2024-03-06  일별급상승  ETF투자방법 2024-03-02  43.91608\n",
       "  1094  2024-03-06  일별급상승  ETF투자방법 2024-03-03  40.32634\n",
       "  1095  2024-03-06  일별급상승  ETF투자방법 2024-03-04  63.21678\n",
       "  1096  2024-03-06  일별급상승  ETF투자방법 2024-03-05  98.32167\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "              기준일자     유형    연관검색어       검색일자       검색량\n",
       "  0     2024-03-06  일별급상승  ETF투자방법 2021-03-05   6.71328\n",
       "  1     2024-03-06  일별급상승  ETF투자방법 2021-03-06   7.17948\n",
       "  2     2024-03-06  일별급상승  ETF투자방법 2021-03-07   9.13752\n",
       "  3     2024-03-06  일별급상승  ETF투자방법 2021-03-08  11.74825\n",
       "  4     2024-03-06  일별급상승  ETF투자방법 2021-03-09  11.56177\n",
       "  ...          ...    ...      ...        ...       ...\n",
       "  1092  2024-03-06  일별급상승  ETF투자방법 2024-03-01  45.17482\n",
       "  1093  2024-03-06  일별급상승  ETF투자방법 2024-03-02  43.91608\n",
       "  1094  2024-03-06  일별급상승  ETF투자방법 2024-03-03  40.32634\n",
       "  1095  2024-03-06  일별급상승  ETF투자방법 2024-03-04  63.21678\n",
       "  1096  2024-03-06  일별급상승  ETF투자방법 2024-03-05  98.32167\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "  55.53,\n",
       "  ['주식'],\n",
       "  'ETF투자방법',\n",
       "  34670.0,\n",
       "  34670.0],\n",
       " [            기준일자     유형   연관검색어       검색일자       검색량\n",
       "  0     2024-03-06  일별급상승  비트코인전망 2021-03-05   8.49893\n",
       "  1     2024-03-06  일별급상승  비트코인전망 2021-03-06   6.47183\n",
       "  2     2024-03-06  일별급상승  비트코인전망 2021-03-07   6.66312\n",
       "  3     2024-03-06  일별급상승  비트코인전망 2021-03-08   6.82252\n",
       "  4     2024-03-06  일별급상승  비트코인전망 2021-03-09   9.01434\n",
       "  ...          ...    ...     ...        ...       ...\n",
       "  1092  2024-03-06  일별급상승  비트코인전망 2024-03-01   8.11902\n",
       "  1093  2024-03-06  일별급상승  비트코인전망 2024-03-02   7.04569\n",
       "  1094  2024-03-06  일별급상승  비트코인전망 2024-03-03   6.69234\n",
       "  1095  2024-03-06  일별급상승  비트코인전망 2024-03-04  10.57651\n",
       "  1096  2024-03-06  일별급상승  비트코인전망 2024-03-05  19.40488\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "              기준일자     유형   연관검색어       검색일자       검색량\n",
       "  0     2024-03-06  일별급상승  비트코인전망 2021-03-05   8.49893\n",
       "  1     2024-03-06  일별급상승  비트코인전망 2021-03-06   6.47183\n",
       "  2     2024-03-06  일별급상승  비트코인전망 2021-03-07   6.66312\n",
       "  3     2024-03-06  일별급상승  비트코인전망 2021-03-08   6.82252\n",
       "  4     2024-03-06  일별급상승  비트코인전망 2021-03-09   9.01434\n",
       "  ...          ...    ...     ...        ...       ...\n",
       "  1092  2024-03-06  일별급상승  비트코인전망 2024-03-01   8.11902\n",
       "  1093  2024-03-06  일별급상승  비트코인전망 2024-03-02   7.04569\n",
       "  1094  2024-03-06  일별급상승  비트코인전망 2024-03-03   6.69234\n",
       "  1095  2024-03-06  일별급상승  비트코인전망 2024-03-04  10.57651\n",
       "  1096  2024-03-06  일별급상승  비트코인전망 2024-03-05  19.40488\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "  83.47,\n",
       "  ['금리'],\n",
       "  '비트코인전망',\n",
       "  78540.0,\n",
       "  78540.0],\n",
       " [            기준일자     유형   연관검색어       검색일자        검색량\n",
       "  0     2024-03-06  일별급상승  샌드박스코인 2021-03-05   6.690403\n",
       "  1     2024-03-06  일별급상승  샌드박스코인 2021-03-06   3.229489\n",
       "  2     2024-03-06  일별급상승  샌드박스코인 2021-03-07   2.618435\n",
       "  3     2024-03-06  일별급상승  샌드박스코인 2021-03-08   4.615402\n",
       "  4     2024-03-06  일별급상승  샌드박스코인 2021-03-09  10.177328\n",
       "  ...          ...    ...     ...        ...        ...\n",
       "  1092  2024-03-06  일별급상승  샌드박스코인 2024-03-01   6.963437\n",
       "  1093  2024-03-06  일별급상승  샌드박스코인 2024-03-02   9.199649\n",
       "  1094  2024-03-06  일별급상승  샌드박스코인 2024-03-03   7.969720\n",
       "  1095  2024-03-06  일별급상승  샌드박스코인 2024-03-04   8.500147\n",
       "  1096  2024-03-06  일별급상승  샌드박스코인 2024-03-05  11.877884\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "              기준일자     유형   연관검색어       검색일자        검색량\n",
       "  0     2024-03-06  일별급상승  샌드박스코인 2021-03-05   6.690403\n",
       "  1     2024-03-06  일별급상승  샌드박스코인 2021-03-06   3.229489\n",
       "  2     2024-03-06  일별급상승  샌드박스코인 2021-03-07   2.618435\n",
       "  3     2024-03-06  일별급상승  샌드박스코인 2021-03-08   4.615402\n",
       "  4     2024-03-06  일별급상승  샌드박스코인 2021-03-09  10.177328\n",
       "  ...          ...    ...     ...        ...        ...\n",
       "  1092  2024-03-06  일별급상승  샌드박스코인 2024-03-01   6.963437\n",
       "  1093  2024-03-06  일별급상승  샌드박스코인 2024-03-02   9.199649\n",
       "  1094  2024-03-06  일별급상승  샌드박스코인 2024-03-03   7.969720\n",
       "  1095  2024-03-06  일별급상승  샌드박스코인 2024-03-04   8.500147\n",
       "  1096  2024-03-06  일별급상승  샌드박스코인 2024-03-05  11.877884\n",
       "  \n",
       "  [1097 rows x 5 columns],\n",
       "  39.74,\n",
       "  ['금리'],\n",
       "  '샌드박스코인',\n",
       "  45210.0,\n",
       "  45210.0]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict['daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keyword_categories': {},\n",
       " 'related_search_terms': {},\n",
       " 'related_search_volume': {},\n",
       " 'up_month': {}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = analysis_instance.keyword_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동기 : 49.392563343048096\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list=['daily','weekly_up','weekly_stay','monthly_up','monthly_stay','monthly_rule']\n",
    "daily_up_trend, weekly_up_trend, weekly_stay_trend, monthly_up_trend, monthly_stay_trend, monthly_rule_trend = [pd.DataFrame() for _ in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_up_info, weekly_up_info, weekly_stay_info, monthly_up_info, monthly_stay_info, monthly_rule_info = [{} for _ in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One or more required columns ['검색일자', '연관검색어', '검색량'] are missing in the DataFrame.\n",
      "One or more required columns ['검색일자', '연관검색어', '검색량'] are missing in the DataFrame.\n",
      "One or more required columns ['검색일자', '연관검색어', '검색량'] are missing in the DataFrame.\n",
      "One or more required columns ['검색일자', '연관검색어', '검색량'] are missing in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "daily_up_trendc=analysis.map_columns_based_on_keys(review_types, 'daily')\n",
    "\n",
    "weekly_up_trend=analysis.map_columns_based_on_keys(review_types, 'weekly_up')\n",
    "\n",
    "weekly_stay_trend=analysis.map_columns_based_on_keys(review_types, 'weekly_stay')\n",
    "\n",
    "monthly_up_trend=analysis.map_columns_based_on_keys(review_types, 'monthly_up')\n",
    "\n",
    "monthly_stay_trend=analysis.map_columns_based_on_keys(review_types, 'monthly_stay')\n",
    "\n",
    "monthly_rule_trend=analysis.map_columns_based_on_keys(review_types, 'monthly_rule')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = ['keyword_categories', 'related_search_terms', \\\n",
    "             'related_search_volume', 'daily_up_info',\\\n",
    "                  'weekly_up_info', 'weekly_stay_info', 'monthly_up_info', \\\n",
    "                    'monthly_stay_info', 'monthly_rule_info', 'up_month']\n",
    "\n",
    "trend_type = dict(zip(['daily_up_trend', 'weekly_up_trend', \\\n",
    "                       'weekly_stay_trend', 'monthly_up_trend', 'monthly_stay_trend', 'monthly_rule_trend'] , \n",
    "                        ['일별 급상승', '주별 급상승', '주별 지속상승', '월별 급상승', '월별 지속상승', '월별 규칙성']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder './data/dict' already exists.\n",
      "Folder './data/types' already exists.\n",
      "Folder './data/json' already exists.\n"
     ]
    }
   ],
   "source": [
    "# 결과 저장을 위한 폴더 경로\n",
    "folders = ['./data/dict', './data/types', './data/json']\n",
    "\n",
    "try:\n",
    "    # 폴더 생성\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        else:\n",
    "            print(f\"Folder '{folder}' already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily_up_trend에 대한 데이터프레임이 존재합니다. CSV 파일로 저장합니다.\n",
      "weekly_up_trend에 대한 데이터프레임이 존재합니다. CSV 파일로 저장합니다.\n",
      "Error for type_eng 'weekly_stay_trend': 'NoneType' object has no attribute 'to_csv'\n",
      "monthly_up_trend에 대한 데이터프레임이 존재합니다. CSV 파일로 저장합니다.\n",
      "Error for type_eng 'monthly_stay_trend': 'NoneType' object has no attribute 'to_csv'\n",
      "Error for type_eng 'monthly_rule_trend': 'NoneType' object has no attribute 'to_csv'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 유형 분류 결과 저장\n",
    "for k in dict_list:\n",
    "    with open(f'./data/dict/{k}.pkl', 'wb') as f:\n",
    "        pickle.dump(eval(f'{k}'), f)\n",
    "\n",
    "for type_eng, type_kor in trend_type.items():\n",
    "    evaluated_df = eval(type_eng)  # 변수의 평가된 결과를 저장\n",
    "    if evaluated_df is not None:  # 평가된 결과가 None이 아니면 CSV로 저장\n",
    "        print(f\"{type_eng}에 대한 데이터프레임이 존재합니다. CSV 파일로 저장합니다.\")\n",
    "        evaluated_df.to_csv(f'./data/types/{type_eng}_result.csv', encoding='utf-8-sig')\n",
    "    else:  # 평가된 결과가 None이면 오류 메시지 출력\n",
    "        print(f\"Error for type_eng '{type_eng}': 'NoneType' object has no attribute 'to_csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 정리 코드\n",
    "\n",
    "\n",
    "make_directory('./data')\n",
    "make_directory('./data/rl_srch')\n",
    "make_directory(f'./data/rl_srch/{day}')  # 키워드별 연관검색어 리스트 저장\n",
    "\n",
    "이걸로 생성된 파일 삭제하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디렉토리 './data'가 삭제되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from utils import remove_directory\n",
    "\n",
    "# 특정 디렉토리 삭제    \n",
    "remove_directory('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로그파일 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# 사용 가능한 CPU 코어의 수를 확인\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "print(f\"Available CPU cores: {cpu_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 세션이 끊겼을 때 어떻게해야 좋을지 판단 로그파일을 인터넷에 깔아서 관리할까? 아니면 딕셔너리로 보이게 해서 관리할까? 라는 생각\n",
    "2. 너무 하드코딩되어있는 부분 존재 이런부분은 처리하기\n",
    "3. missing데이터 같은 경우 딕셔너리로 관리해서 daily나 weekly일때 다르게 구분하기 편하게 하기\n",
    "4. 로그파일로 따로 관리하는거 좋은가? 에 대한 생각해보기\n",
    "5. 주석같은거 중요한거마다 하기\n",
    "6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
